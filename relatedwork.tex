\chapter{Related Work}
\label{c:relw}

In this section, we describe a brief introduction to the most notable research on the navigation for visually impaired.
Visually impaired people can not have information about their location or the direction with respect to the traffic or obstacles on the way.
The conventional ways of the guide dog and long cane can help to find out the obstacles on the way, not help to provide information of their position.
Navigation system helps people to travel in a convenience and independence.
People Sensor \cite{peoplesensor} uses pyroelectric and ultrasound sensor to distinguish between a person and object obstruction in the path of the user.
It helps to reduce the embarrassment through unintended contact with people and object in the directional path.
There are many ways to find the location of the users \cite{survey}.

%In this work, we build a navigation system to detect the traffic light in a public street for visually impaired.
%There has some existing systems for helping the blind and visually impaired find their way at indoor and outdoor.
After the introduction of Global Positioning System (GPS) at the 1980s, many navigation assistant systems integrate GPS for visually impaired.
Loomis \cite{loomis1,loomis,loomis2} was one of the first to propose the navigation system using DGPS and FM correction data receiver to get the location of the visually impaired.

There has some commercially released system for outdoor navigation for blind and visually impaired users.
Ariadne GPS \cite{arigps} developed by Ciaffoni is one of the first GPS apps for blind and visually impaired.
Other commercially released apps for iPhone and Android devices are BlindSquare \cite{blindsq} developed by MIPsoft and ViaOpta Nav \cite{viaopta} developed by Novartis Corporation etc.
These apps use GPS to inform users the current location, give an announcement of user points of interest and use open source map to navigate.
Seeing Assistant move app \cite{seeing} developed by Transition Technologies is the only GPS app for blind people that lets the user operate the app through speech commands.

Other systems that use GPS to find the userâ€™s location are MoBic \cite{mobic}, BrailleNote GPS and Trekker developed by Humanware group \cite{human}, etc. BrailleNote GPS is commercially available and provides the user with nearby location names and the distance to the destination along the path. 
However, there is a shortcoming of GPS.
A GPS sensor is ineffective at indoor.
Some studies proposed and implemented differential GPS which can provide better accuracy \cite{drishti2,gps}.
It is costly and needs fixed ground station, only efficient for outdoors.
Furthermore, the GPS signal can not be tracked when blind people move through tall buildings or high walls or trees.

Alternative approaches have been proposed to assist the blind people, such as ultrasound \cite{drishti} or radio frequency identification (RFID) \cite{rfid} transponders or virtual blind cane to detect obstacles using laser and inertial measurement unit (IMU) \cite {virtual}
Although WLAN transmitters or RFID tags or WiFi is low-cost technologies, installing them dedicatedly in the whole city would be expensive and inconvenient.
Slight changes of the scenes also hamper to the navigation process.

In order to be extensively applicable, navigation system design needs to be wearable, low cost and mobile technology based.
To achieve this aim we propose a computer vision based navigation system for visually impaired.
The research on vision based localization system is active in recent years.
The map based navigation method requires a global map to make a decision for the navigation \cite{online,map,map2}.
For this purpose, sequential images of the environment are registered in a database.
Then to get accurate location and orientation for real world images image -to-image matches with the database.
Another navigation method creates a map while moving and then use that for navigation \cite{fly,fly2,fly3}. 
\cite{visual} proposed a system with a wearable stereo camera to estimate the ego-motion using visual odometry method.

Traffic light detection is an important part of the outdoor navigation for the visually impaired.
There is a significant research of traffic light detection for an autonomous selfdriving car and driving assistance system \cite{traffic_turan,selfdrive,traffic,traffic2,traffic3}.
\cite{traffic_turan} introduces a technique to detect traffic light state using vehicle localization and prior knowledge of traffic light location.
In recent years traffic light detection is divided into two categories: model-based and learning-based \cite{survey_traffic}.
The model based \cite{model,model2} detection approach creates a heuristic model that rely on color or shape information and this approach is dominant and popular in past decades.
The color information is quite significant as traffic light color is an important feature to distinct it from the scenario.
Primarily to find the region of interest (ROI) and to classify the traffic light state we use the color information.
To detect and recognize the color, the detector defines the heuristical threshold of color in selected color space.
The RGB color space is most common as the input video frames are in this space \cite{rgb2}.
Because of the lightening changes problem, and the color and intensity information is mixed in all the channels of  RGB color space as we discussed in \S\ref{s:color_space}, the values of RGB channel change in different condition.
The other researcher on traffic light recognition is working with the color space which is more immune to lightening condition and hue distribution is much narrower \cite{hsv2}.
The color can vary in different conditions, so to make the model more robust, distinctive shape of traffic light is also used by applying the Hough transform on an edge map \cite{hough,hough2,signalguru} or by using radial symmetry \cite{radial,radial2}.
The shape information is fused with the color information, applying them as a filter after color segmentation \cite{signalguru}.
For our system to detect traffic light color, we use the HSV space due to the description of color in HSV space is similar to the human perspective and we use Hough circle transform to get the shape information of the traffic light. 

For outdoor navigation system traffic light detection is only a part of the system either for autonomous vehicle or pedestrian navigation.
It is important to use less time to detect the traffic light.
We can use the information from the sensor like GPS, accelerometer, gyroscope to get the position of the traffic light. \cite{sensor,sensor2,sensor3}
For the navigation purpose, we need a portable system.
Nowadays smartphone uses is growing and it has the internal sensor that we can use to get the position of the traffic light.

For autonomous selfdriving car or driving assistance system, the position of the traffic light is stable with respect to the vehicle while driving.
\cite{signalguru} introduces a system, Signalguru, which get the position of the traffic light from the sensor data of smartphone.
Since the traffic light is always in the upper part of the scenario, they processed the upper half of the frame to detect the traffic light.
In the context of pedestrian navigation, the camera of a smartphone is not always fixed because of the movement of the body part while walking \cite{sensor_pedestrian,sensor_pedestrian2}.
So it is important to track the traffic light position from the sensor hints.
In our system, we use the sensor hints at each video frame to get the relative position of traffic light from the previous video frame and finally processed that area to detect the traffic light state.

Learning based model \cite{learning,learning2} is another category to detect traffic light states.
SVM classifier together with HOG features \cite{selfdrive} is one of the popular learning based detector in computer vision research areas.
The learning based aggregated channel feature (ACF) \cite{acf,acf2,lisa_cvpr} detector largely used in traffic light detection and provide outperform result.
Traffic light detection using deep learning is introduced in \cite{cnn,cnn2,cnn3}, where a convolutional neural network (CNN) model detects and recognizes traffic light states using the region of interest information from the smartphone GPS sensor.

In our system, we use the model based computer vision technique to detect and recognize the traffic light states.
Our main approach is to use the sensor hints to improve the computation time and the misdetection rate.
If we adopt these learning based approaches as our detection method with the sensor hint the result can be approved more.  





